# üöÄ Gu√≠a Completa: Predicci√≥n de Series Temporales en Google Vertex AI

Esta gu√≠a documenta el proceso completo para predecir el consumo de **CPU y RAM** de servidores utilizando Google Cloud Vertex AI con AutoML Forecasting.

---

## üìä Entendiendo los Datos

### ¬øPor qu√© necesitamos 2 archivos CSV?

En **Forecasting**, debemos separar claramente el "pasado para aprender" del "contexto para predecir".

| Archivo | Prop√≥sito | Contenido | Estructura de Datos |
|---------|-----------|-----------|---------------------|
| **A: server_metrics_training.csv** | üìö **El Libro de Texto** | Historial completo (ej. 60 d√≠as) | Todas las columnas con valores reales |
| **B: prediction_input.csv** | üìù **El Examen** | Ventana de contexto reciente (48h) + filas futuras vac√≠as | Target columnas con `null`/`NaN` en el futuro |

#### Archivo A: El Dataset de Entrenamiento

- **Objetivo**: Entrenar el modelo
- **L√≥gica**: El modelo aprende patrones hist√≥ricos (ej: "Los lunes por la ma√±ana la CPU aumenta")
- **Uso**: Solo durante la fase de training

#### Archivo B: El Input de Predicci√≥n

- **Objetivo**: Generar predicciones mediante Batch Prediction
- **L√≥gica**: Proporciona contexto reciente para que el modelo "tome impulso" y prediga el futuro
- **Requisito cr√≠tico**: Las filas futuras deben tener el timestamp pero el target vac√≠o (`NaN`) para indicar a Vertex AI qu√© valores debe predecir

> ‚ö†Ô∏è **Importante**: Vertex AI necesita el Context Window completo para generar predicciones precisas.

---

## üéØ Creaci√≥n del Dataset y Entrenamiento

### Configuraci√≥n del Dataset

1. **Tipo**: Tabular ‚Üí Forecasting
2. **Fuente**: `server_metrics_training.csv`
3. **Esquema (Schema)**:

| Rol | Columna | Descripci√≥n |
|-----|---------|-------------|
| üéØ **Target** | `cpu_usage` | Variable a predecir |
| üî¢ **Series Identifier** | `server_id` | Identifica cada servidor individualmente |
| ‚è∞ **Timestamp** | `timestamp` | Variable temporal |
| üìà **Covariate** | `ram_usage` | Variable auxiliar predictora |
| üè∑Ô∏è **Attributes** | `region`, `os_type` | Caracter√≠sticas categ√≥ricas |

### Par√°metros del Entrenamiento

- **M√©todo**: AutoML
- **Forecast Horizon**: 24 horas (cu√°nto tiempo al futuro predecir)
- **Context Window**: 48 horas (cu√°nto hist√≥rico analizar)
- **Presupuesto**: 1 node hour
- **Arquitectura**: TiDE (TimeSeries Dense Encoder)

---

## ‚ö†Ô∏è El Dilema del Despliegue: Endpoint vs Batch

### ‚ùå Por qu√© fall√≥ "Deploy to Endpoint"

**Error encontrado**: `Invalid model for deployment`

| M√©todo | Caracter√≠sticas | Id√≥neo para Forecasting |
|--------|----------------|------------------------|
| **Online Prediction (Endpoint)** | Respuesta en milisegundos, una fila a la vez | ‚ùå No compatible |
| **Batch Prediction** | Procesamiento por lotes, analiza secuencias largas | ‚úÖ Recomendado |

#### Explicaci√≥n t√©cnica

Un **Endpoint** funciona como un chat en tiempo real, pero los modelos de Forecasting necesitan:

- Analizar el **Context Window** completo (ej. 48 horas de historia)
- Procesar secuencias temporales complejas
- Realizar c√°lculos computacionalmente intensivos

> üí° **Soluci√≥n**: Usar **Batch Prediction** para procesar archivos completos con todas las series temporales de forma eficiente.

### ‚úÖ Ventajas de Batch Prediction

- **Costo-eficiente**: Solo pagas por el tiempo de procesamiento
- **Escalable**: Maneja grandes vol√∫menes de datos hist√≥ricos
- **Robusto**: Procesa m√∫ltiples series temporales simult√°neamente
- **Flexible**: Resultados exportables a BigQuery para an√°lisis

---

## üîÆ Ejecuci√≥n de la Predicci√≥n

### Paso 1: Preparar el archivo de input

```python
# Generar prediction_input.csv con:
# - √öltimas 48h de datos reales (Context Window)
# - Pr√≥ximas 24h con timestamps pero target = NaN
```

### Paso 2: Subir a Cloud Storage

Ubicaci√≥n: `gs://your-bucket/prediction_input.csv`

### Paso 3: Configurar Batch Prediction

En **Vertex AI** ‚Üí **Batch Predictions** ‚Üí **Create**:

| Configuraci√≥n | Valor |
|---------------|-------|
| **Modelo** | `cpu_predict` (modelo entrenado) |
| **Origen** | CSV en Cloud Storage |
| **Destino** | BigQuery ‚Üí Dataset `test` |
| **Monitoring** | Off (para evitar errores de Skew en pruebas) |

### Paso 4: Ajuste cr√≠tico de Compute

> ‚ö†Ô∏è **Problema com√∫n**: Si la regi√≥n (ej. Madrid `europe-southwest1`) no tiene stock de m√°quinas `n1-highmem-8`

**Soluciones**:
- Cambiar en **Advanced Options** a `n1-standard-4`
- Usar regi√≥n con m√°s disponibilidad como `us-central1`

### Paso 5: Ejecutar y monitorear

Estado esperado: ‚úÖ **Finished**

Los resultados aparecen autom√°ticamente en la tabla de BigQuery especificada.

---

## üìà Visualizaci√≥n de Resultados en Looker Studio

### Configuraci√≥n del gr√°fico

#### 1. Fuente de datos
- Tabla BigQuery: `predictions_*` generada por el batch job

#### 2. Tipo de gr√°fico
- **Line Chart** (Gr√°fico de l√≠neas) o **Time Series Chart**

#### 3. Configuraci√≥n detallada

| Elemento | Configuraci√≥n | Detalle |
|----------|---------------|---------|
| **Dimensi√≥n (Eje X)** | `timestamp` | ‚ö†Ô∏è Cambiar tipo de "Fecha" a **"Fecha y Hora"** (Date Hour) |
| **Breakdown** | `server_id` | Para visualizar las 5 series en colores diferentes |
| **M√©trica (Eje Y)** | `predicted_cpu_usage.value` | Valor de la predicci√≥n |
| **Ordenar** | `timestamp` ‚Üí Ascendente | Para cronolog√≠a de izquierda a derecha |

#### 4. Estilo visual

- **Interpolaci√≥n**: Curva suave
- **N√∫mero de series**: 5 (asegurar visualizaci√≥n de todos los servidores)
- **Leyenda**: Activada con identificadores de servidor

---

## üéì Conclusiones Clave

- **Separaci√≥n de datos**: Training vs Prediction input son fundamentales en forecasting
- **Batch es el camino**: Los modelos de forecasting en Vertex AI no soportan endpoints online
- **Context Window**: Proporcionar suficiente historia (48h recomendadas) mejora la precisi√≥n
- **Infraestructura**: Considerar disponibilidad regional de compute resources
- **Visualizaci√≥n**: Date Hour granularity es esencial para series temporales horarias

---

## üìö Recursos Adicionales

- [Vertex AI Forecasting Overview](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/overview)
- [Batch Predictions Documentation](https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/get-predictions)
- [TiDE Architecture Details](https://cloud.google.com/blog/products/ai-machine-learning/vertex-ai-forecasting)

---

**√öltima actualizaci√≥n**: Noviembre 2025  
**Versi√≥n**: 1.0