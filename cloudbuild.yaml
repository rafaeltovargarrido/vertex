steps:
  # 1. Construir
  - name: 'gcr.io/cloud-builders/docker'
    args: [
      'build', 
      '-t', 'europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:latest', 
      '.'
    ]

  # 2. Subir
  - name: 'gcr.io/cloud-builders/docker'
    args: [
      'push', 
      'europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:latest'
    ]

# -------------------------------------------------------------------------
  # 3. Lanzar entrenamiento Y ESPERAR A QUE TERMINE
  # -------------------------------------------------------------------------
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: /bin/bash
    args:
      - -c
      - |
        # 1. Crear el trabajo y capturar su ID
        JOB_ID=$(gcloud ai custom-jobs create \
          --region=${_REGION} \
          --display-name=training-job-$BUILD_ID \
          --worker-pool-spec=machine-type=n1-standard-4,replica-count=1,container-image-uri=europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:$COMMIT_SHA \
          --args=--model_dir=gs://${_BUCKET}/model_output/ \
          --format="value(name)")
        
        echo "Trabajo de entrenamiento iniciado: $JOB_ID"
        
        # 2. Esperar a que termine (Streaming de logs)
        # Esto bloquear√° Cloud Build hasta que el entrenamiento finalice
        gcloud ai custom-jobs stream-logs $JOB_ID --region=${_REGION}

  # 4. Desplegar
  - name: 'python:3.9-slim'
    entrypoint: /bin/sh
    args:
      - -c
      - |
        pip install google-cloud-aiplatform
        python deploy.py \
          --project_id=$PROJECT_ID \
          --region=${_REGION} \
          --bucket=${_BUCKET} \
          --name=mi-modelo-regresion

images:
  - 'europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:latest'

substitutions:
    _REGION: europe-west4
    _BUCKET: dataflow_vertex
    _REPO_NAME: images