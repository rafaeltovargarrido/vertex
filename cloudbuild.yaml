steps:
  # 1. Construir (Usamos la variable nueva)
  - name: 'gcr.io/cloud-builders/docker'
    args: [
      'build', 
      '-t', 'europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:${_IMAGE_TAG}', 
      '-t', 'europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:latest',
      '.'
    ]

  # 2. Subir
  - name: 'gcr.io/cloud-builders/docker'
    args: [
      'push', 
      'europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:${_IMAGE_TAG}'
    ]

  # 3. Entrenar
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: /bin/bash
    args:
      - -c
      - |
        # Usamos $$ para escapar variables bash y ${_IMAGE_TAG} para la imagen
        JOB_ID=$$(gcloud ai custom-jobs create \
          --region=${_REGION} \
          --quiet \
          --display-name=training-job-$BUILD_ID \
          --worker-pool-spec=machine-type=n1-standard-4,replica-count=1,container-image-uri=europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:${_IMAGE_TAG} \
          --args=--model_dir=gs://${_BUCKET}/model_output/ \
          --format="value(name)")   
      
  
  # 4. Desplegar Endpoint 
  #- name: 'python:3.9-slim'
  #  entrypoint: /bin/sh
  #  args:
  #    - -c
  #    - |
  #      pip install google-cloud-aiplatform
  #      python deploy.py \
  #        --project_id=$PROJECT_ID \
  #        --region=${_REGION} \
  #        --bucket=${_BUCKET} \
  #        --name=mi-modelo-regresion
images:
  - 'europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:${_IMAGE_TAG}'

substitutions:
    _REGION: europe-west4
    _BUCKET: dataflow_vertex
    _REPO_NAME: images
    _IMAGE_TAG: latest  # Valor por defecto por seguridad