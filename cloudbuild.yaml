steps:
  # 1. Construir
  - name: 'gcr.io/cloud-builders/docker'
    args: [
      'build', 
      '-t', 'europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:latest', 
      '.'
    ]

  # 2. Subir
  - name: 'gcr.io/cloud-builders/docker'
    args: [
      'push', 
      'europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:latest'
    ]

  # 3. Entrenar (CORREGIDO)
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args:
      - ai
      - custom-jobs
      - create
      - --region=${_REGION}
      - --display-name=training-job-$BUILD_ID
      # Aquí definimos la máquina y la imagen LIMPIAS (sin env=)
      - --worker-pool-spec=machine-type=n1-standard-4,replica-count=1,container-image-uri=europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:latest
      # Aquí pasamos el argumento a tu script python
      - --args=--model_dir=gs://${_BUCKET}/model_output/

  # 4. Desplegar
  - name: 'python:3.9-slim'
    entrypoint: /bin/sh
    args:
      - -c
      - |
        pip install google-cloud-aiplatform
        python deploy.py \
          --project_id=$PROJECT_ID \
          --region=${_REGION} \
          --bucket=${_BUCKET} \
          --name=mi-modelo-regresion

images:
  - 'europe-docker.pkg.dev/$PROJECT_ID/${_REPO_NAME}/training-image:latest'

substitutions:
    _REGION: europe-west4
    _BUCKET: dataflow_vertex
    _REPO_NAME: images